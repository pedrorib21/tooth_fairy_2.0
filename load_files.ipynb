{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 14:44:32.371706: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-05 14:44:32.408521: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-05 14:44:32.409379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-05 14:44:32.995449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from training.datagenerator import DataGenerator\n",
    "from models import pointnet_seg\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vedo import show, Points, settings\n",
    "\n",
    "settings.default_backend = 'k3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Teeth3DS_train_test_split/training_lower.txt\", \"r\") as f:\n",
    "    train_ex = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Teeth3DS_train_test_split/testing_lower.txt\", \"r\") as f:\n",
    "    test_ex = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_PATH = \"data/lower\"\n",
    "folders = os.listdir(LOWER_PATH)\n",
    "obj_files = [\n",
    "    os.path.join(LOWER_PATH, f, f\"{f}_lower.obj\")\n",
    "    for f in folders\n",
    "    if f\"{f}_lower\" in train_ex\n",
    "]\n",
    "label_files = [\n",
    "    os.path.join(LOWER_PATH, f, f\"{f}_lower.json\")\n",
    "    for f in folders\n",
    "    if f\"{f}_lower\" in train_ex\n",
    "]\n",
    "assert len(obj_files) == len(label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"obj_file\": obj_files, \"label_file\": label_files})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"obj_file\": obj_files, \"label_file\": label_files})\n",
    "labels_list = []\n",
    "for row in df.itertuples():\n",
    "    with open(row.label_file, \"r\") as file:\n",
    "        labels = json.load(file)\n",
    "    labels_list.append(labels[\"labels\"])\n",
    "df[\"labels\"] = labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.json\", \"r\") as f:\n",
    "    teeth_name_label_dict = json.load(f)\n",
    "\n",
    "LABELS_TO_IDENTIFY = [teeth_name_label_dict[name] for name in [\"LeftMandibularSecondMolar\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_selected_teeth'] = df['labels'].apply(lambda labels: set(LABELS_TO_IDENTIFY).issubset(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 77, 223]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.has_selected_teeth.values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data to train\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_train = df[df[\"has_selected_teeth\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7379/2386187063.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_train[\"selected_teeth\"]=df_to_train[\"labels\"].apply(lambda labels:[label if label in LABELS_TO_IDENTIFY else 0 for label in labels])\n"
     ]
    }
   ],
   "source": [
    "df_to_train[\"selected_teeth\"]=df_to_train[\"labels\"].apply(lambda labels:[label if label in LABELS_TO_IDENTIFY else 0 for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      [32, 0, 41, 36, 36, 31, 33, 47, 0, 0, 42, 45, ...\n",
       "3      [34, 0, 0, 43, 0, 0, 32, 0, 0, 0, 35, 47, 45, ...\n",
       "5      [0, 46, 47, 0, 0, 0, 0, 45, 42, 44, 45, 34, 37...\n",
       "8      [0, 0, 0, 0, 0, 0, 36, 34, 0, 45, 35, 0, 32, 0...\n",
       "11     [48, 0, 43, 0, 41, 0, 0, 0, 0, 44, 0, 0, 0, 0,...\n",
       "                             ...                        \n",
       "295    [36, 0, 0, 0, 46, 45, 0, 46, 32, 0, 36, 0, 42,...\n",
       "296    [35, 0, 0, 37, 45, 36, 41, 0, 46, 0, 45, 31, 3...\n",
       "297    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34, 0, 31...\n",
       "298    [45, 0, 47, 45, 31, 43, 45, 33, 45, 45, 46, 0,...\n",
       "299    [0, 0, 0, 47, 0, 0, 0, 34, 46, 0, 35, 0, 46, 0...\n",
       "Name: labels, Length: 223, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_train[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45,\n",
       " 41,\n",
       " 33,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 33,\n",
       " 45,\n",
       " 31,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 42,\n",
       " 36,\n",
       " 36,\n",
       " 32,\n",
       " 0,\n",
       " 45,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 32,\n",
       " 36,\n",
       " 32,\n",
       " 42,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 35,\n",
       " 46,\n",
       " 43,\n",
       " 35,\n",
       " 0,\n",
       " 32,\n",
       " 45,\n",
       " 35,\n",
       " 35,\n",
       " 34,\n",
       " 34,\n",
       " 36,\n",
       " 0,\n",
       " 42,\n",
       " 0,\n",
       " 42,\n",
       " 36,\n",
       " 43,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 32,\n",
       " 45,\n",
       " 0,\n",
       " 46,\n",
       " 45,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 43,\n",
       " 33,\n",
       " 0,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 42,\n",
       " 34,\n",
       " 35,\n",
       " 32,\n",
       " 35,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 42,\n",
       " 46,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 42,\n",
       " 34,\n",
       " 0,\n",
       " 34,\n",
       " 32,\n",
       " 0,\n",
       " 35,\n",
       " 32,\n",
       " 0,\n",
       " 32,\n",
       " 0,\n",
       " 36,\n",
       " 42,\n",
       " 0,\n",
       " 45,\n",
       " 36,\n",
       " 0,\n",
       " 41,\n",
       " 32,\n",
       " 44,\n",
       " 0,\n",
       " 43,\n",
       " 36,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 35,\n",
       " 43,\n",
       " 35,\n",
       " 46,\n",
       " 35,\n",
       " 36,\n",
       " 0,\n",
       " 44,\n",
       " 34,\n",
       " 41,\n",
       " 45,\n",
       " 36,\n",
       " 33,\n",
       " 32,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 0,\n",
       " 44,\n",
       " 31,\n",
       " 36,\n",
       " 36,\n",
       " 43,\n",
       " 0,\n",
       " 43,\n",
       " 46,\n",
       " 35,\n",
       " 31,\n",
       " 33,\n",
       " 36,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 35,\n",
       " 0,\n",
       " 43,\n",
       " 31,\n",
       " 36,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 0,\n",
       " 45,\n",
       " 32,\n",
       " 43,\n",
       " 32,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 41,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 32,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 34,\n",
       " 36,\n",
       " 41,\n",
       " 46,\n",
       " 36,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 46,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 33,\n",
       " 35,\n",
       " 31,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 0,\n",
       " 32,\n",
       " 34,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 31,\n",
       " 35,\n",
       " 46,\n",
       " 43,\n",
       " 32,\n",
       " 46,\n",
       " 46,\n",
       " 44,\n",
       " 44,\n",
       " 33,\n",
       " 45,\n",
       " 32,\n",
       " 36,\n",
       " 46,\n",
       " 31,\n",
       " 35,\n",
       " 41,\n",
       " 45,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 31,\n",
       " 46,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 34,\n",
       " 46,\n",
       " 32,\n",
       " 34,\n",
       " 35,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 32,\n",
       " 43,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 44,\n",
       " 0,\n",
       " 33,\n",
       " 0,\n",
       " 46,\n",
       " 45,\n",
       " 0,\n",
       " 44,\n",
       " 35,\n",
       " 45,\n",
       " 0,\n",
       " 36,\n",
       " 35,\n",
       " 46,\n",
       " 33,\n",
       " 44,\n",
       " 43,\n",
       " 35,\n",
       " 46,\n",
       " 46,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 45,\n",
       " 36,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 43,\n",
       " 41,\n",
       " 43,\n",
       " 0,\n",
       " 32,\n",
       " 46,\n",
       " 35,\n",
       " 31,\n",
       " 43,\n",
       " 33,\n",
       " 46,\n",
       " 46,\n",
       " 43,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 44,\n",
       " 31,\n",
       " 34,\n",
       " 43,\n",
       " 32,\n",
       " 32,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 43,\n",
       " 41,\n",
       " 33,\n",
       " 45,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 45,\n",
       " 35,\n",
       " 0,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 31,\n",
       " 31,\n",
       " 43,\n",
       " 45,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 42,\n",
       " 32,\n",
       " 34,\n",
       " 44,\n",
       " 33,\n",
       " 46,\n",
       " 34,\n",
       " 32,\n",
       " 41,\n",
       " 43,\n",
       " 35,\n",
       " 31,\n",
       " 34,\n",
       " 35,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 33,\n",
       " 46,\n",
       " 0,\n",
       " 33,\n",
       " 42,\n",
       " 0,\n",
       " 42,\n",
       " 35,\n",
       " 45,\n",
       " 42,\n",
       " 35,\n",
       " 42,\n",
       " 44,\n",
       " 36,\n",
       " 33,\n",
       " 0,\n",
       " 44,\n",
       " 31,\n",
       " 43,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 42,\n",
       " 41,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 42,\n",
       " 0,\n",
       " 32,\n",
       " 33,\n",
       " 32,\n",
       " 32,\n",
       " 45,\n",
       " 41,\n",
       " 45,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 33,\n",
       " 42,\n",
       " 36,\n",
       " 46,\n",
       " 41,\n",
       " 32,\n",
       " 0,\n",
       " 36,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 36,\n",
       " 46,\n",
       " 0,\n",
       " 45,\n",
       " 46,\n",
       " 43,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 31,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 35,\n",
       " 46,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 46,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 32,\n",
       " 44,\n",
       " 31,\n",
       " 46,\n",
       " 36,\n",
       " 46,\n",
       " 33,\n",
       " 44,\n",
       " 44,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 0,\n",
       " 46,\n",
       " 33,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 33,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 43,\n",
       " 32,\n",
       " 43,\n",
       " 32,\n",
       " 41,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 34,\n",
       " 0,\n",
       " 34,\n",
       " 41,\n",
       " 0,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 35,\n",
       " 44,\n",
       " 34,\n",
       " 46,\n",
       " 0,\n",
       " 42,\n",
       " 34,\n",
       " 0,\n",
       " 46,\n",
       " 36,\n",
       " 0,\n",
       " 35,\n",
       " 46,\n",
       " 31,\n",
       " 43,\n",
       " 35,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 41,\n",
       " 32,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 45,\n",
       " 44,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 34,\n",
       " 46,\n",
       " 35,\n",
       " 0,\n",
       " 32,\n",
       " 44,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 46,\n",
       " 0,\n",
       " 36,\n",
       " 33,\n",
       " 41,\n",
       " 32,\n",
       " 0,\n",
       " 36,\n",
       " 42,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 42,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 36,\n",
       " 44,\n",
       " 35,\n",
       " 0,\n",
       " 34,\n",
       " 34,\n",
       " 43,\n",
       " 36,\n",
       " 43,\n",
       " 0,\n",
       " 32,\n",
       " 36,\n",
       " 0,\n",
       " 44,\n",
       " 36,\n",
       " 36,\n",
       " 32,\n",
       " 43,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 35,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 46,\n",
       " 36,\n",
       " 0,\n",
       " 35,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 36,\n",
       " 32,\n",
       " 0,\n",
       " 32,\n",
       " 45,\n",
       " 0,\n",
       " 35,\n",
       " 44,\n",
       " 0,\n",
       " 42,\n",
       " 32,\n",
       " 33,\n",
       " 41,\n",
       " 42,\n",
       " 0,\n",
       " 34,\n",
       " 46,\n",
       " 36,\n",
       " 46,\n",
       " 0,\n",
       " 43,\n",
       " 35,\n",
       " 43,\n",
       " 36,\n",
       " 45,\n",
       " 45,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 46,\n",
       " 0,\n",
       " 35,\n",
       " 42,\n",
       " 33,\n",
       " 31,\n",
       " 45,\n",
       " 45,\n",
       " 41,\n",
       " 35,\n",
       " 42,\n",
       " 35,\n",
       " 31,\n",
       " 46,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 41,\n",
       " 0,\n",
       " 36,\n",
       " 43,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 32,\n",
       " 0,\n",
       " 36,\n",
       " 44,\n",
       " 43,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 33,\n",
       " 43,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 44,\n",
       " 44,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 46,\n",
       " 46,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 41,\n",
       " 36,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 36,\n",
       " 42,\n",
       " 32,\n",
       " 46,\n",
       " 32,\n",
       " 0,\n",
       " 33,\n",
       " 46,\n",
       " 0,\n",
       " 36,\n",
       " 46,\n",
       " 0,\n",
       " 45,\n",
       " 46,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 31,\n",
       " 31,\n",
       " 41,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 43,\n",
       " 42,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 46,\n",
       " 44,\n",
       " 0,\n",
       " 32,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 46,\n",
       " 0,\n",
       " 44,\n",
       " 41,\n",
       " 46,\n",
       " 44,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 31,\n",
       " 31,\n",
       " 42,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 35,\n",
       " 45,\n",
       " 45,\n",
       " 0,\n",
       " 35,\n",
       " 33,\n",
       " 33,\n",
       " 44,\n",
       " 43,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 36,\n",
       " 42,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 46,\n",
       " 45,\n",
       " 41,\n",
       " 45,\n",
       " 35,\n",
       " 34,\n",
       " 32,\n",
       " 31,\n",
       " 34,\n",
       " 46,\n",
       " 44,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 46,\n",
       " 31,\n",
       " 34,\n",
       " 44,\n",
       " 46,\n",
       " 46,\n",
       " 0,\n",
       " 32,\n",
       " 36,\n",
       " 46,\n",
       " 36,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 41,\n",
       " 32,\n",
       " 44,\n",
       " 35,\n",
       " 35,\n",
       " 32,\n",
       " 0,\n",
       " 36,\n",
       " 33,\n",
       " 35,\n",
       " 44,\n",
       " 0,\n",
       " 33,\n",
       " 46,\n",
       " 34,\n",
       " 44,\n",
       " 44,\n",
       " 0,\n",
       " 33,\n",
       " 34,\n",
       " 0,\n",
       " 45,\n",
       " 35,\n",
       " 42,\n",
       " 42,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 42,\n",
       " 35,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 43,\n",
       " 34,\n",
       " 31,\n",
       " 45,\n",
       " 46,\n",
       " 43,\n",
       " 42,\n",
       " 44,\n",
       " 41,\n",
       " 32,\n",
       " 32,\n",
       " 0,\n",
       " 35,\n",
       " 45,\n",
       " 44,\n",
       " 36,\n",
       " 46,\n",
       " 36,\n",
       " 0,\n",
       " 33,\n",
       " 46,\n",
       " 44,\n",
       " 33,\n",
       " 0,\n",
       " 46,\n",
       " 46,\n",
       " 34,\n",
       " 31,\n",
       " 31,\n",
       " 45,\n",
       " 36,\n",
       " 31,\n",
       " 45,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 42,\n",
       " 0,\n",
       " 43,\n",
       " 0,\n",
       " 36,\n",
       " 46,\n",
       " 35,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 34,\n",
       " 45,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 0,\n",
       " 43,\n",
       " 0,\n",
       " 45,\n",
       " 45,\n",
       " 0,\n",
       " 46,\n",
       " 36,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 45,\n",
       " 43,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 0,\n",
       " 31,\n",
       " 0,\n",
       " 46,\n",
       " 36,\n",
       " 32,\n",
       " 0,\n",
       " 45,\n",
       " 41,\n",
       " 42,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 41,\n",
       " 43,\n",
       " 34,\n",
       " 0,\n",
       " 36,\n",
       " 41,\n",
       " 45,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 31,\n",
       " 45,\n",
       " 0,\n",
       " 36,\n",
       " 43,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 44,\n",
       " 31,\n",
       " 44,\n",
       " 32,\n",
       " 35,\n",
       " 45,\n",
       " 31,\n",
       " 44,\n",
       " 0,\n",
       " 41,\n",
       " 31,\n",
       " 45,\n",
       " 45,\n",
       " 0,\n",
       " 44,\n",
       " 36,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 33,\n",
       " 33,\n",
       " 31,\n",
       " 36,\n",
       " 0,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 31,\n",
       " 36,\n",
       " 46,\n",
       " 31,\n",
       " 33,\n",
       " 46,\n",
       " 46,\n",
       " 42,\n",
       " 43,\n",
       " 32,\n",
       " 31,\n",
       " 46,\n",
       " 31,\n",
       " 35,\n",
       " 45,\n",
       " 36,\n",
       " 36,\n",
       " 46,\n",
       " 42,\n",
       " 0,\n",
       " 36,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unique 17, Unique [ 0 31 32 33 34 35 36 37 38 41 42 43 44 45 46 47 48]\n"
     ]
    }
   ],
   "source": [
    "# how many unique labels are there?\n",
    "\n",
    "unique_labels = []\n",
    "\n",
    "for f in label_files:\n",
    "    with open(f, \"r\") as file:\n",
    "        labels = json.load(file)\n",
    "    # Store class\n",
    "    unique_labels.append(np.unique(labels[\"labels\"]))\n",
    "\n",
    "unique_labels = np.unique(np.concatenate(unique_labels))\n",
    "print(f\"Num unique {len(unique_labels)}, Unique {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    obj_files, label_files, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(x_train, y_train, unique_labels=unique_labels)\n",
    "validation_generator = DataGenerator(x_val, y_val, unique_labels=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000, 3)\n",
      "(1, 10000, 17)\n",
      "[0. 1.]\n",
      "(1, 10000, 3)\n",
      "(1, 10000, 17)\n",
      "[0. 1.]\n",
      "(1, 10000, 3)\n",
      "(1, 10000, 17)\n",
      "[0. 1.]\n",
      "(1, 10000, 3)\n",
      "(1, 10000, 17)\n",
      "[0. 1.]\n",
      "(1, 10000, 3)\n",
      "(1, 10000, 17)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for t in training_generator:\n",
    "    print(t[0].shape)\n",
    "    print(t[1].shape)\n",
    "    i += 1\n",
    "    print(np.unique(t[1]))\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 22:41:46.087776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-02 22:41:46.088631: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = pointnet_seg.get_shape_segmentation_model(10000, num_classes=len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 3)]            0         []                            \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 64)             256       ['input_1[0][0]']             \n",
      " _1_conv (Conv1D)                                                                                 \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 64)             256       ['input_transformation_block_1\n",
      " _1_batch_norm (BatchNormal                                         _conv[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 64)             0         ['input_transformation_block_1\n",
      " _1_relu (Activation)                                               _batch_norm[0][0]']           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 128)            8320      ['input_transformation_block_1\n",
      " _2_conv (Conv1D)                                                   _relu[0][0]']                 \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 128)            512       ['input_transformation_block_2\n",
      " _2_batch_norm (BatchNormal                                         _conv[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 128)            0         ['input_transformation_block_2\n",
      " _2_relu (Activation)                                               _batch_norm[0][0]']           \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 1024)           132096    ['input_transformation_block_2\n",
      " _3_conv (Conv1D)                                                   _relu[0][0]']                 \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 1024)           4096      ['input_transformation_block_3\n",
      " _3_batch_norm (BatchNormal                                         _conv[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 1024)           0         ['input_transformation_block_3\n",
      " _3_relu (Activation)                                               _batch_norm[0][0]']           \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 1024)                 0         ['input_transformation_block_3\n",
      " alMaxPooling1D)                                                    _relu[0][0]']                 \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 512)                  524800    ['global_max_pooling1d[0][0]']\n",
      " _1_1_dense (Dense)                                                                               \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 512)                  2048      ['input_transformation_block_1\n",
      " _1_1_batch_norm (BatchNorm                                         _1_dense[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 512)                  0         ['input_transformation_block_1\n",
      " _1_1_relu (Activation)                                             _1_batch_norm[0][0]']         \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 256)                  131328    ['input_transformation_block_1\n",
      " _2_1_dense (Dense)                                                 _1_relu[0][0]']               \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 256)                  1024      ['input_transformation_block_2\n",
      " _2_1_batch_norm (BatchNorm                                         _1_dense[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 256)                  0         ['input_transformation_block_2\n",
      " _2_1_relu (Activation)                                             _1_batch_norm[0][0]']         \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, 9)                    2313      ['input_transformation_block_2\n",
      " _final (Dense)                                                     _1_relu[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 3, 3)                 0         ['input_transformation_block_f\n",
      "                                                                    inal[0][0]']                  \n",
      "                                                                                                  \n",
      " input_transformation_block  (None, None, 3)              0         ['input_1[0][0]',             \n",
      " _mm (Dot)                                                           'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " features_64_conv (Conv1D)   (None, None, 64)             256       ['input_transformation_block_m\n",
      "                                                                    m[0][0]']                     \n",
      "                                                                                                  \n",
      " features_64_batch_norm (Ba  (None, None, 64)             256       ['features_64_conv[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " features_64_relu (Activati  (None, None, 64)             0         ['features_64_batch_norm[0][0]\n",
      " on)                                                                ']                            \n",
      "                                                                                                  \n",
      " features_128_1_conv (Conv1  (None, None, 128)            8320      ['features_64_relu[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " features_128_1_batch_norm   (None, None, 128)            512       ['features_128_1_conv[0][0]'] \n",
      " (BatchNormalization)                                                                             \n",
      "                                                                                                  \n",
      " features_128_1_relu (Activ  (None, None, 128)            0         ['features_128_1_batch_norm[0]\n",
      " ation)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " features_128_2_conv (Conv1  (None, None, 128)            16512     ['features_128_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " features_128_2_batch_norm   (None, None, 128)            512       ['features_128_2_conv[0][0]'] \n",
      " (BatchNormalization)                                                                             \n",
      "                                                                                                  \n",
      " features_128_2_relu (Activ  (None, None, 128)            0         ['features_128_2_batch_norm[0]\n",
      " ation)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " transformed_features_1_con  (None, None, 64)             8256      ['features_128_2_relu[0][0]'] \n",
      " v (Conv1D)                                                                                       \n",
      "                                                                                                  \n",
      " transformed_features_1_bat  (None, None, 64)             256       ['transformed_features_1_conv[\n",
      " ch_norm (BatchNormalizatio                                         0][0]']                       \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " transformed_features_1_rel  (None, None, 64)             0         ['transformed_features_1_batch\n",
      " u (Activation)                                                     _norm[0][0]']                 \n",
      "                                                                                                  \n",
      " transformed_features_2_con  (None, None, 128)            8320      ['transformed_features_1_relu[\n",
      " v (Conv1D)                                                         0][0]']                       \n",
      "                                                                                                  \n",
      " transformed_features_2_bat  (None, None, 128)            512       ['transformed_features_2_conv[\n",
      " ch_norm (BatchNormalizatio                                         0][0]']                       \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " transformed_features_2_rel  (None, None, 128)            0         ['transformed_features_2_batch\n",
      " u (Activation)                                                     _norm[0][0]']                 \n",
      "                                                                                                  \n",
      " transformed_features_3_con  (None, None, 1024)           132096    ['transformed_features_2_relu[\n",
      " v (Conv1D)                                                         0][0]']                       \n",
      "                                                                                                  \n",
      " transformed_features_3_bat  (None, None, 1024)           4096      ['transformed_features_3_conv[\n",
      " ch_norm (BatchNormalizatio                                         0][0]']                       \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " transformed_features_3_rel  (None, None, 1024)           0         ['transformed_features_3_batch\n",
      " u (Activation)                                                     _norm[0][0]']                 \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 1024)                 0         ['transformed_features_3_relu[\n",
      " obalMaxPooling1D)                                                  0][0]']                       \n",
      "                                                                                                  \n",
      " transformed_features_1_1_d  (None, 512)                  524800    ['global_max_pooling1d_1[0][0]\n",
      " ense (Dense)                                                       ']                            \n",
      "                                                                                                  \n",
      " transformed_features_1_1_b  (None, 512)                  2048      ['transformed_features_1_1_den\n",
      " atch_norm (BatchNormalizat                                         se[0][0]']                    \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " transformed_features_1_1_r  (None, 512)                  0         ['transformed_features_1_1_bat\n",
      " elu (Activation)                                                   ch_norm[0][0]']               \n",
      "                                                                                                  \n",
      " transformed_features_2_1_d  (None, 256)                  131328    ['transformed_features_1_1_rel\n",
      " ense (Dense)                                                       u[0][0]']                     \n",
      "                                                                                                  \n",
      " transformed_features_2_1_b  (None, 256)                  1024      ['transformed_features_2_1_den\n",
      " atch_norm (BatchNormalizat                                         se[0][0]']                    \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " transformed_features_2_1_r  (None, 256)                  0         ['transformed_features_2_1_bat\n",
      " elu (Activation)                                                   ch_norm[0][0]']               \n",
      "                                                                                                  \n",
      " transformed_features_final  (None, 16384)                4210688   ['transformed_features_2_1_rel\n",
      "  (Dense)                                                           u[0][0]']                     \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 128, 128)             0         ['transformed_features_final[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " transformed_features_mm (D  (None, None, 128)            0         ['features_128_2_relu[0][0]', \n",
      " ot)                                                                 'reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " features_512_conv (Conv1D)  (None, None, 512)            66048     ['transformed_features_mm[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " features_512_batch_norm (B  (None, None, 512)            2048      ['features_512_conv[0][0]']   \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " features_512_relu (Activat  (None, None, 512)            0         ['features_512_batch_norm[0][0\n",
      " ion)                                                               ]']                           \n",
      "                                                                                                  \n",
      " pre_maxpool_block_conv (Co  (None, None, 2048)           1050624   ['features_512_relu[0][0]']   \n",
      " nv1D)                                                                                            \n",
      "                                                                                                  \n",
      " pre_maxpool_block_batch_no  (None, None, 2048)           8192      ['pre_maxpool_block_conv[0][0]\n",
      " rm (BatchNormalization)                                            ']                            \n",
      "                                                                                                  \n",
      " pre_maxpool_block_relu (Ac  (None, None, 2048)           0         ['pre_maxpool_block_batch_norm\n",
      " tivation)                                                          [0][0]']                      \n",
      "                                                                                                  \n",
      " global_features (MaxPoolin  (None, None, 2048)           0         ['pre_maxpool_block_relu[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)        (None, None, 2048)           0         ['global_features[0][0]']     \n",
      "                                                                                                  \n",
      " segmentation_input (Concat  (None, None, 3008)           0         ['features_64_relu[0][0]',    \n",
      " enate)                                                              'features_128_1_relu[0][0]', \n",
      "                                                                     'features_128_2_relu[0][0]', \n",
      "                                                                     'transformed_features_mm[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'features_512_relu[0][0]',   \n",
      "                                                                     'tf.tile[0][0]']             \n",
      "                                                                                                  \n",
      " segmentation_features_conv  (None, None, 128)            385152    ['segmentation_input[0][0]']  \n",
      "  (Conv1D)                                                                                        \n",
      "                                                                                                  \n",
      " segmentation_features_batc  (None, None, 128)            512       ['segmentation_features_conv[0\n",
      " h_norm (BatchNormalization                                         ][0]']                        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " segmentation_features_relu  (None, None, 128)            0         ['segmentation_features_batch_\n",
      "  (Activation)                                                      norm[0][0]']                  \n",
      "                                                                                                  \n",
      " segmentation_head (Conv1D)  (None, None, 17)             2193      ['segmentation_features_relu[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7371610 (28.12 MB)\n",
      "Trainable params: 7357658 (28.07 MB)\n",
      "Non-trainable params: 13952 (54.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 263s 1s/step - loss: 0.8312 - accuracy: 0.6822 - val_loss: 2.6910 - val_accuracy: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff78c5017d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_generator, validation_data=validation_generator, verbose=1, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj_files = [\n",
    "    os.path.join(LOWER_PATH, f, f\"{f}_lower.obj\")\n",
    "    for f in folders\n",
    "    if f\"{f}_lower\" in test_ex\n",
    "]\n",
    "test_label_files = [\n",
    "    os.path.join(LOWER_PATH, f, f\"{f}_lower.json\")\n",
    "    for f in folders\n",
    "    if f\"{f}_lower\" in test_ex\n",
    "]\n",
    "assert len(test_obj_files) == len(test_label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(test_obj_files, test_label_files, unique_labels=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 556ms/step\n"
     ]
    }
   ],
   "source": [
    "for t in test_generator:\n",
    "    inp = t[0]\n",
    "    result = model.predict(t[0])\n",
    "    prediction = np.argmax(result, axis=-1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Points object for visualization\n",
    "pointcloud = Points(inp[0])\n",
    "show(pointcloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
